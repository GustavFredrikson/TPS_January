{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP_Finland</th>\n",
       "      <th>GDP_Norway</th>\n",
       "      <th>GDP_Sweden</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>234.440</td>\n",
       "      <td>385.802</td>\n",
       "      <td>505.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>240.608</td>\n",
       "      <td>368.827</td>\n",
       "      <td>515.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>255.017</td>\n",
       "      <td>398.394</td>\n",
       "      <td>541.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>275.580</td>\n",
       "      <td>437.000</td>\n",
       "      <td>555.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>268.782</td>\n",
       "      <td>405.510</td>\n",
       "      <td>533.880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GDP_Finland  GDP_Norway  GDP_Sweden\n",
       "year                                     \n",
       "2015      234.440     385.802     505.104\n",
       "2016      240.608     368.827     515.655\n",
       "2017      255.017     398.394     541.019\n",
       "2018      275.580     437.000     555.455\n",
       "2019      268.782     405.510     533.880"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\", parse_dates=['date'])\n",
    "test_df = pd.read_csv(\"data/test.csv\", parse_dates=['date'])\n",
    "gdp_df = pd.read_csv(\"data/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv\")\n",
    "gdp_df.set_index('year', inplace=True)\n",
    "gdp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleMart</td>\n",
       "      <td>Kaggle Sticker</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Mug</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Finland</td>\n",
       "      <td>KaggleRama</td>\n",
       "      <td>Kaggle Hat</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id       date  country       store         product  num_sold\n",
       "0       0 2015-01-01  Finland  KaggleMart      Kaggle Mug       329\n",
       "1       1 2015-01-01  Finland  KaggleMart      Kaggle Hat       520\n",
       "2       2 2015-01-01  Finland  KaggleMart  Kaggle Sticker       146\n",
       "3       3 2015-01-01  Finland  KaggleRama      Kaggle Mug       572\n",
       "4       4 2015-01-01  Finland  KaggleRama      Kaggle Hat       911"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_loss(y_true, y_pred):\n",
    "    return np.abs(y_true - y_pred) / (y_true + np.abs(y_pred)) * 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time step feature\n",
    "https://www.kaggle.com/c/tabular-playground-series-jan-2022/discussion/298831"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_step_feature(df):\n",
    "    t0 = np.datetime64('2015-01-01')\n",
    "    df['time_step'] = (df.date - t0).astype('timedelta64[D]').astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA which makes sense\n",
    "https://www.kaggle.com/ambrosm/tpsjan22-01-eda-which-makes-sense/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Official public holidays an unofficial days, Norway, Sweden, Finland\n",
    "https://www.kaggle.com/c/tabular-playground-series-jan-2022/discussion/298990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date country            event        type\n",
      "0 2015-01-01  Norway   New Year's Day      public\n",
      "1 2015-02-08  Norway     Mother's Day  unofficial\n",
      "2 2015-02-14  Norway  Valentine's Day  unofficial\n",
      "3 2015-03-20  Norway   Spring Equinox       other\n",
      "4 2015-03-29  Norway      Palm Sunday  unofficial\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 432 entries, 0 to 431\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   date     432 non-null    datetime64[ns]\n",
      " 1   country  432 non-null    object        \n",
      " 2   event    432 non-null    object        \n",
      " 3   type     432 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 13.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "holidays = pd.read_csv(\"data/holidays.csv\", parse_dates=['date'])\n",
    "print(holidays.head(), end='\\n\\n')\n",
    "print(holidays.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Days til next holiday\n",
    "https://www.kaggle.com/c/tabular-playground-series-jan-2022/discussion/298411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "\n",
    "def days_til_next_holi(country, date):\n",
    "    country_holidays = holidays.CountryHoliday(country, years=[date.year, date.year+1])\n",
    "    next_date = min([day for day in country_holidays if day >= date])\n",
    "    return (next_date - date).days\n",
    "\n",
    "def is_holi(country, date):\n",
    "    country_holidays = holidays.CountryHoliday(country, years=date.year)\n",
    "    return date in country_holidays\n",
    "\n",
    "def add_holidays(df):\n",
    "    df = df.copy()\n",
    "    df['isHoliday'] = df.apply(lambda x: is_holi(x['country'], x['date'].date()), axis=1)\n",
    "    df['daysTillHoliday'] = df.apply(lambda x: days_til_next_holi(x['country'], x['date'].date()), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering from linear model\n",
    "https://www.kaggle.com/ambrosm/tpsjan22-03-linear-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer(df):\n",
    "    df = df.copy()\n",
    "    def get_gdp(row):\n",
    "        country = 'GDP_' + row.country\n",
    "        return gdp_df.loc[row.date.year, country]\n",
    "    \n",
    "    new_df = pd.DataFrame({\n",
    "        'gdp': np.log(df.apply(get_gdp, axis=1)),\n",
    "        'wd4': df.date.dt.weekday == 4, # Friday\n",
    "        'wd56': df.date.dt.weekday >= 5, # Saturday and sunday\n",
    "    })\n",
    "    new_df['country'] = df['country']\n",
    "    new_df['date'] = df['date']\n",
    "    new_df = add_holidays(new_df)\n",
    "    new_df.drop(['country', 'date'], axis=1, inplace=True)\n",
    "    \n",
    "    # One hot encoding\n",
    "    for country in ['Finland', 'Norway']:\n",
    "        new_df[country] = df.country == country\n",
    "    new_df['KaggleRama'] = df.store == 'KaggleRama'\n",
    "    for product in ['Kaggle Mug', 'Kaggle Hat']:\n",
    "        new_df[product] = df['product'] == product\n",
    "    \n",
    "    # Fourier series of Seasonal variations\n",
    "    dayofyear = df.date.dt.dayofyear\n",
    "    for k in range(3):\n",
    "        new_df[f'sin{k}'] = np.sin(dayofyear / 365 * 2 * math.pi * k)\n",
    "        new_df[f'cos{k}'] = np.cos(dayofyear / 365 * 2 * math.pi * k)\n",
    "        new_df[f'mug_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Mug']\n",
    "        new_df[f'mug_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Mug']\n",
    "        new_df[f'hat_sin{k}'] = new_df[f'sin{k}'] * new_df['Kaggle Hat']\n",
    "        new_df[f'hat_cos{k}'] = new_df[f'cos{k}'] * new_df['Kaggle Hat']\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "   Unnamed: 0     gdp    wd4   wd56  isHoliday  daysTillHoliday  Finland  \\\n",
      "0           0  5.4572  False  False       True                0     True   \n",
      "1           1  5.4572  False  False       True                0     True   \n",
      "2           2  5.4572  False  False       True                0     True   \n",
      "3           3  5.4572  False  False       True                0     True   \n",
      "4           4  5.4572  False  False       True                0     True   \n",
      "\n",
      "   Norway  KaggleRama  Kaggle Mug  ...  mug_cos1  hat_sin1  hat_cos1  \\\n",
      "0   False       False        True  ...  0.999852  0.000000  0.000000   \n",
      "1   False       False       False  ...  0.000000  0.017213  0.999852   \n",
      "2   False       False       False  ...  0.000000  0.000000  0.000000   \n",
      "3   False        True        True  ...  0.999852  0.000000  0.000000   \n",
      "4   False        True       False  ...  0.000000  0.017213  0.999852   \n",
      "\n",
      "       sin2      cos2  mug_sin2  mug_cos2  hat_sin2  hat_cos2  num_sold  \n",
      "0  0.034422  0.999407  0.034422  0.999407  0.000000  0.000000     329.0  \n",
      "1  0.034422  0.999407  0.000000  0.000000  0.034422  0.999407     520.0  \n",
      "2  0.034422  0.999407  0.000000  0.000000  0.000000  0.000000     146.0  \n",
      "3  0.034422  0.999407  0.034422  0.999407  0.000000  0.000000     572.0  \n",
      "4  0.034422  0.999407  0.000000  0.000000  0.034422  0.999407     911.0  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "['Unnamed: 0', 'gdp', 'wd4', 'wd56', 'isHoliday', 'daysTillHoliday', 'Finland', 'Norway', 'KaggleRama', 'Kaggle Mug', 'Kaggle Hat', 'sin0', 'cos0', 'mug_sin0', 'mug_cos0', 'hat_sin0', 'hat_cos0', 'sin1', 'cos1', 'mug_sin1', 'mug_cos1', 'hat_sin1', 'hat_cos1', 'sin2', 'cos2', 'mug_sin2', 'mug_cos2', 'hat_sin2', 'hat_cos2']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(\"data/Featured_Train.csv\") and os.path.exists(\"data/Featured_Test.csv\"):\n",
    "    print(\"Reading files...\")\n",
    "    new_train_df = pd.read_csv(\"data/Featured_Train.csv\")\n",
    "    new_test_df = pd.read_csv(\"data/Featured_Test.csv\")\n",
    "else:\n",
    "    print(\"Creating dataframes...\")\n",
    "    new_train_df = engineer(train_df)\n",
    "    # new_train_df['date'] = train_df.date\n",
    "    new_train_df['num_sold'] = train_df.num_sold.astype(np.float32)\n",
    "    new_test_df = engineer(test_df)\n",
    "    # Save them\n",
    "    new_train_df.to_csv(\"data/Featured_Train.csv\")\n",
    "    new_test_df.to_csv(\"data/Featured_Test.csv\")\n",
    "\n",
    "print(new_train_df.head())\n",
    "\n",
    "features = new_test_df.columns\n",
    "for df in [new_train_df, new_test_df]:\n",
    "    df[features] = df[features].astype(np.float32)\n",
    "print(list(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  <class 'xgboost.sklearn.XGBRegressor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavfredrikson/Documents/GitHub/TPS_January/env/lib/python3.10/site-packages/numpy/core/_methods.py:163: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asanyarray(a)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4378,) (8761,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     y_val \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     23\u001b[0m     test_acc\u001b[38;5;241m.\u001b[39mappend(smape_loss(y_test, y_val))\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean training SMAPE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(train_acc)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean testing SMAPE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(test_acc)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/GitHub/TPS_January/env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3471\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3472\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/TPS_January/env/lib/python3.10/site-packages/numpy/core/_methods.py:179\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    176\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    177\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    181\u001b[0m     ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mtrue_divide(\n\u001b[1;32m    182\u001b[0m             ret, rcount, out\u001b[38;5;241m=\u001b[39mret, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4378,) (8761,) "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "import lightgbm as lgb\n",
    "\n",
    "models = [XGBRegressor(), LinearRegression(), lgb.LGBMRegressor(), BayesianRidge()]\n",
    "\n",
    "X = new_train_df.drop(\"num_sold\", axis=1).values\n",
    "y = new_train_df['num_sold'].values\n",
    "for model in models:\n",
    "    tscv = TimeSeriesSplit(n_splits=5, gap=5)\n",
    "    print('Training model: ', model.__class__)\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    for epoch, (train_index, test_index) in enumerate(tscv.split(X), start=1):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_hat = model.predict(X_train)\n",
    "        train_acc.append(smape_loss(y_train, y_hat))\n",
    "        y_val = model.predict(X_test)\n",
    "        test_acc.append(smape_loss(y_test, y_val))\n",
    "\n",
    "    print(f\"Mean training SMAPE: {np.mean(train_acc)}\")\n",
    "    print(f\"Mean testing SMAPE: {np.mean(test_acc)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "067285970e749128406118d28689d915c6c8834da6929e6b727880331d0940b5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('lightML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
